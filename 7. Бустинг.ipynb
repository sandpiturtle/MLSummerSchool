{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://habrahabr.ru/company/ods/blog/327250/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Современные фреймворки градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T10:26:28.787747",
     "start_time": "2017-07-26T10:26:28.780755"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T10:26:28.935057",
     "start_time": "2017-07-26T10:26:28.918740"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_titanic():\n",
    "    df = sns.load_dataset('titanic')\n",
    "\n",
    "    X, y = df.drop(['survived'], axis=1), df.survived\n",
    "\n",
    "    X[\"embarked\"] = X[\"embarked\"].fillna(\"S\")\n",
    "    X[\"fare\"].fillna(X[\"fare\"].median(), inplace=True)\n",
    "    X[\"embark_town\"] = X[\"embark_town\"].fillna(X.embark_town.value_counts().index[0]) \n",
    "    \n",
    "    average_age_titanic   = X[\"age\"].mean()\n",
    "    std_age_titanic       = X[\"age\"].std()\n",
    "    count_nan_age_titanic = X[\"age\"].isnull().sum()\n",
    "    rand_1 = np.random.randint(average_age_titanic - std_age_titanic, \n",
    "                               average_age_titanic + std_age_titanic, \n",
    "                               size=count_nan_age_titanic)\n",
    "    X[\"age\"][np.isnan(X[\"age\"])] = rand_1\n",
    "\n",
    "    X.drop(['deck', 'alive'], axis=1, inplace=True)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T10:26:29.175342",
     "start_time": "2017-07-26T10:26:29.070396"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = get_preprocessed_titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T10:26:29.418912",
     "start_time": "2017-07-26T10:26:29.401908"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T10:26:29.720900",
     "start_time": "2017-07-26T10:26:29.624581"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T10:26:29.816534",
     "start_time": "2017-07-26T10:26:29.813073"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 192837465\n",
    "np.random.seed = SEED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T10:26:31.280916",
     "start_time": "2017-07-26T10:26:31.181302"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T10:26:39.382546",
     "start_time": "2017-07-26T10:26:39.359518"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8136924803591471, 0.019309372092127106)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X.values, y)\n",
    "np.mean(scores), 2*np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T10:26:34.231368",
     "start_time": "2017-07-26T10:26:33.751384"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80471380471380483, 0.025196346038881826)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(AdaBoostClassifier(LogisticRegression(), random_state=SEED), X, y)\n",
    "np.mean(scores), 2*np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:15:45.548797",
     "start_time": "2017-07-25T11:15:45.163576"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78226711560044893, 0.039008186749680734)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(AdaBoostClassifier(DecisionTreeClassifier(random_state=SEED), random_state=SEED), X, y)\n",
    "np.mean(scores), 2*np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:15:53.169859",
     "start_time": "2017-07-25T11:15:50.420855"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.77665544332211001, 0.020816203132425791)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(AdaBoostClassifier(RandomForestClassifier(random_state=SEED), random_state=SEED), X, y)\n",
    "np.mean(scores), 2*np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Какие параметры для настройки есть?\n",
    "\n",
    "* __`n_estimators`__ - сколько по сути итераций бустинга выполнять, обучая новый классификатор на остатках старого.\n",
    "* __`learning_rate`__ - скорость обучения\n",
    "\n",
    "##### Как настраивать?\n",
    "\n",
    "* Используйте простой классификатор для бустинга.\n",
    "* Этот простой классификатор не должен быть очень хорош в обобщающей способности, не нужно его сильно регуляризовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:17:22.251367",
     "start_time": "2017-07-25T11:17:22.248454"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:17:23.060842",
     "start_time": "2017-07-25T11:17:23.057706"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:17:24.084165",
     "start_time": "2017-07-25T11:17:23.834920"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82267115600448937, 0.042707738699080698)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(GradientBoostingClassifier(random_state=SEED), X, y)\n",
    "np.mean(scores), 2*np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Какие параметры для настройки?\n",
    "\n",
    "Относящиеся к деревьям:\n",
    "\n",
    "* __`min_samples_split`__ - б&#243;льшие значения, конечно, защищают от лишних сплитов по шумовым объектам, но слишком большие значения могут привести к недообучению. Можно опираться на значения ~0.5-1% от числа объектов в выборке. \n",
    "    * _Использовать CV для настройки._\n",
    "\n",
    "\n",
    "* __`min_samples_leaf`__ - как и `min_samples_split`, является регуляризатором переобучения. В целом _меньшие значения можно использовать, когда речь идет о несбалансированных классах_, так как и области, содержащие эти редкие классы, небольшие.\n",
    "    * _Использовать CV для настройки._\n",
    "    \n",
    "\n",
    "* __`min_weight_fraction_leaf`__ - похож на `min_samples_leaf`, но формулируется как _доля_ от общего числа объектов вместо _числа_. Настраивайте или этот параметр, или `min_samples_leaf` по усмотрению.\n",
    "    * _Использовать CV для настройки._\n",
    "\n",
    "\n",
    "* __`max_depth`__ - максимальная глубина дерева. Используется для контроля переобучения, так как б&#243;льшая глубина позволяет модели выучить неочевидные взаимосвязи относительно каждого из объектов выборки.\n",
    "    * Обычно в диапазоне 3-10.\n",
    "    * _Использовать CV для настройки._\n",
    "\n",
    "\n",
    "* __`max_leaf_nodes`__ - максимальное число терминальных узлов, то есть листов дерева. Может быть использовано вместо `max_depth`. Т.к. деревья бинарные, дерево глубиной $N$ порождает _не более_ $2^N$ листов. Если задан этот параметр, GBM будет игнорировать `max_depth`.\n",
    "    * _Использовать CV для настройки._\n",
    "\n",
    "\n",
    "* __`max_features`__ - количество признаков, которое рассматривается при поиске лучшего сплита. Признаки при этом выбираются случайно. Как правило, $\\sqrt{M}$, где $M$ - число признаков, работает отлично, но можно попробовать поднять эту отметку до 30-40% от общего числа признаков. \n",
    "    * `NB`: Большие значения могут привести к переобучению.\n",
    "    \n",
    "Относящиеся к бустингу:\n",
    "\n",
    "* __`learning_rate`__ - данный параметр определяет вклад каждого из деревьев на финальное предсказание. \n",
    "    * Величина отражает мощность каждого вклада каждым деревом в финальный результат.\n",
    "    * Меньшие значения более предпочтительны, так как они делают модель более робастной к специфическим параметрам дерева и таким образом повышают его обобщающую способность.\n",
    "    * В то же время меньшие значения тянут за собой большее количество деревьев, что делает общую стоимость вычислений больше.\n",
    "\n",
    "\n",
    "* __`n_estimators`__ - количество деревьев, которое нужно построить. \n",
    "    * Несмотря на то, что GBM достаточно робастен при большом количестве деревьев, он все равно может переобучиться. \n",
    "    * Зафиксируете определенный `learning_rate` и найдите оптимальное количество деревьев с помощью CV.\n",
    "\n",
    "\n",
    "* __`subsample`__ - доля объектов, которая выделяется для обучения каждого из деревьев (подвыборка формируется простым случайным выбором).\n",
    "    * Значения чуть меньшие 1 делают модель робастнее, так как уменьшают вариантивность подвыборок.\n",
    "    * Обычно значение ~0.8 работает норм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Как настраивать?\n",
    "\n",
    "1. Выберите относительно большую скорость обучения (`learning rate`). Обычно это 0.1, но и иногда есть смысл выбрать из диапазона 0.05-0.2.\n",
    "\n",
    "2. Выберите оптимальное количество деревьев при зафиксированной скорости обучения. Ориентируйтесь на 40-70. В том числе на этом шаге есть смысл взять такое количество, которое вас устраивает скоростью работы на конкретном компьютере, так как эту конфигурацию вам еще использовать для проверки множества сценариев (п.3).\n",
    "\n",
    "3. Подберите оптимальные параметры деревьев, зафиксировав `learning_rate` и `n_estimators`.\n",
    "\n",
    "4. Уменьшите `learning_rate`, увеличьте `n_estimators`, чтобы получить более робастные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:21:19.051497",
     "start_time": "2017-07-25T11:21:19.038395"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:26:43.477783",
     "start_time": "2017-07-25T11:26:43.474849"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:21:20.709105",
     "start_time": "2017-07-25T11:21:20.558241"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81593714927048255, 0.024793178489758143)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(XGBClassifier(seed=SEED), X, y)\n",
    "np.mean(scores), 2*np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем XGBoost интереснее, чем GBM?\n",
    "\n",
    "1. Регуляризация из коробки.\n",
    "2. Параллелится на ядра и процессоры на \"ура\".\n",
    "3. Может работать с датафреймами с пропусками в значениях.\n",
    "4. Предоставляет механизм кросс-валидации после каждой из итераций, что позволяет за единственный прогон понять, сколько итераций бустинга достаточно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Какие параметры для настройки?\n",
    "\n",
    "* __`booster [default=gbtree]`__ - тип модели. Всего 2 варианта: \n",
    "    * `gbtree` - деревья\n",
    "    * `gblinear` - линейные модели\n",
    "\n",
    "Дальше речь пойдет только о бустинге деревьев, так как они почти всегда ($\\lim\\rightarrow1)$ превосходят линейные модели.\n",
    "\n",
    "Относящиеся к деревьям:\n",
    "\n",
    "* __`eta [default=0.3]`__ - аналог `learning_rate`. Если вы используете sklearn-подобные обертки вроде XGBClassifier, то этот параметр и будет называться `learning_rate`.\n",
    "    * Разумно перебирать из диапазона 0.01-0.2.\n",
    "\n",
    "\n",
    "* __`min_child_weight [default=1]`__ - определяет минимальную сумму весов всех объектов в дочернем узле. Параметр похож на `min_child_leaf` в GBM, но не совсем: имеется в виду сумма весов объектов, в то время как в GBM имеется в виду просто количество объектов.\n",
    "    * Позволяет управлять переобучением: б&#243;льшие значения не дают модели захватывать слишком частные взаимосвязи между объектами.\n",
    "    * Слишком низкие значения ведут к недообучению.\n",
    "    * _Использовать CV для настройки._\n",
    "    \n",
    "\n",
    "* __`max_depth [default=6]`__ - глубина, такая же, как и в GBM.\n",
    "    * _Использовать CV для настройки._\n",
    "    * Типичный диапазон: 3-10.\n",
    "    \n",
    "\n",
    "* __`max_leaf_nodes`__ - то же, что и в GBM. См. GBM.\n",
    "\n",
    "\n",
    "* __`gamma [default=0]`__ - узел дерева будет разделен, если только в результате этого разделения будет уменьшено значение функции потерь. Параметр $\\gamma$ задает границу величины этого уменьшения. Такой параметр делает алгоритм более консервативным. Значения, очевидно, опираются на выбранную в рамках задачи функцию потерь, и должен быть выбрать особо.\n",
    "\n",
    "\n",
    "* __`max_delta_step [default=0]`__ - заставляет вес (считай, вклад) каждого дерева быть не меньше некоторого порога. В результате принимаемые обновления в бустинге становятся увереннее, и обновления более значимы. Тем-не-менее, этот параметр обычно оставляют равным значению по умолчанию, хотя в случаях _очень несбалансированной выборки_ может помочь.\n",
    "\n",
    "\n",
    "* __`subsample [default=1]`__ - то же, что и в GBM. \n",
    "    * Обычно 0.5-1.\n",
    "\n",
    "\n",
    "* __`colsample_bytree [default=1]`__ - то же, что и `max_features` в GBM.\n",
    "    * В XGB пробуют в интервале 0.5-1.\n",
    "\n",
    "\n",
    "* __`colsample_bylevel [default=1]`__ - обычно не используется, всю работу берет на себя предыдущий параметр.\n",
    "\n",
    "\n",
    "* __`lambda [default=1]`__ - то же, что и $\\alpha$ в $L_2$-регуляризации знакомого Ridge. Обычно не используется. Если вы используете sklearn-подобные обертки вроде XGBClassifier, то этот параметр и будет называться `reg_lambda`.\n",
    "\n",
    "\n",
    "* __`alpha [default=0]`__ - то же, что и $\\alpha$ в $L_1$-регуляризации знакомого Lasso. Может быть использован в очень высокоразмерном признаковом пространстве. Если вы используете sklearn-подобные обертки вроде XGBClassifier, то этот параметр и будет называться `reg_alpha`.\n",
    "\n",
    "\n",
    "* __`scale_pos_weight [default=1]`__ - значения, большие чем 0, могут быть использованы в случае очень несбалансированных классов для более быстрого обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Как настраивать?\n",
    "\n",
    "1. Выберите относительно большую скорость обучения (`learning rate`). Обычно это 0.1, но и иногда есть смысл выбрать из диапазона 0.05-0.3.\n",
    "\n",
    "2. Выберите оптимальное количество деревьев при зафиксированной скорости обучения. У XGB есть полезная функция `cv`, которая выполяет перекрестную проверку после каждой из итерации бустинга и возвращает оптимальное количество деревьев.\n",
    "\n",
    "3. Подберите оптимальные параметры деревьев, зафиксировав `learning_rate` и `n_estimators`:\n",
    "    * max_depth\n",
    "    * min_child_weight \n",
    "    * gamma \n",
    "    * subsample \n",
    "    * colsample_bytree\n",
    "\n",
    "4. Подберите параметры регуляризации:\n",
    "    * reg_lambda\n",
    "    * reg_alpha\n",
    "\n",
    "5. Уменьшите `learning_rate`, выберите лучшие модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:29:24.246260",
     "start_time": "2017-07-25T11:29:24.224390"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:29:25.192464",
     "start_time": "2017-07-25T11:29:25.030544"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8271604938271605, 0.016797564025921096)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LGBMClassifier(seed=SEED), X, y)\n",
    "np.mean(scores), 2*np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем интересен LightGBM?\n",
    "\n",
    "* Меньшее потребление памяти\n",
    "* Говорят, что по точности не хуже, а то и лучше\n",
    "* Может вычисляться на GPU\n",
    "* И считать очень большие объемы данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM делает акцент на построении дерева по листьям, а не уровень за уровнем, за счет чего выигрывает в параллелизме. Поэтому авторы советуют в настройке сделать акцент на __`num_leaves`__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры в большинстве своем настраиваются по аналогии с XGB и GBM. Однако можно дать несколько рекомендаций:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Чтобы достичь большей точности\n",
    "\n",
    "1. Используйте большее значение __`max_bin`__.\n",
    "2. Уменьшайте __`learning_rate`__, увеличивайте __`num_iterations`__.\n",
    "3. Можно попробовать увеличить __`num_leaves`__, но нужно смотреть за переобучением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Чтобы бороться с переобучением\n",
    "\n",
    "* Уменьшайте __`max_bin`__\n",
    "* Уменьшайте __`num_leaves`__\n",
    "* Используйте __`min_data_in_leaf`__ и __`min_sum_hessian_in_leaf`__\n",
    "* Используйте бэггинг, задав параметры __`bagging_fraction`__ и __`bagging_freq`__\n",
    "* Используйте подпространства признаков меньшей размерности через __`feature_fraction`__\n",
    "* Регуляризация здесь осуществляется с помощью параметров __`lambda_l1`__, __`lambda_l2`__ и __`min_gain_to_split`__\n",
    "* Задействуйте __`max_depth`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Легенда гласит, что оно еще быстрее LightGBM в распределенных вычислениях.\n",
    "\n",
    "http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/gbm.html#defining-a-gbm-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://habrahabr.ru/company/yandex/blog/333522/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:35:08.007581",
     "start_time": "2017-07-25T11:35:07.981385"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:37:20.222138",
     "start_time": "2017-07-25T11:37:13.398562"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82042648709315369, 0.025983921218384328)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(CatBoostClassifier(random_seed=SEED), X.values, y)\n",
    "np.mean(scores), 2*np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:37:40.193162",
     "start_time": "2017-07-25T11:37:40.189880"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T11:38:24.469645",
     "start_time": "2017-07-25T11:38:24.467060"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clf.fit(X.values, y, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
