{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый раз, принимая некоторое решение, например, стоит ли идти играть в теннис (_почему бы и нет, окей?_), мы проверяем, осознанно и неосознанно, множество факторов, которые можно представить в виде дерева:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/play_tennis.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое такое условие - элементарный вопрос, подразумевающий ответ _\"да\"_ или _\"нет\"_. В то время очевидно, что такая структура может легко масштабироваться, рости, захватывая даже сложные сценарии.\n",
    "\n",
    "Именно поэтому неудивительно, что __деревья принятия решений__ применяются в областях, где необходимость в построении такого рода проверок должна быть автоматизирована, например, в банковском кредитном скоринге (проверке, можно ли клиенту предоставить кредит):\n",
    "\n",
    "1. Какой возраст у клиента? Если меньше 18, то отказываем в кредите, иначе продолжаем.\n",
    "2. Какая зарплата у клиента? Если меньше 50 тысяч рублей, то переходим к шагу 3, иначе к шагу 4.\n",
    "3. Какой стаж у клиента? Если меньше 10 лет, то не выдаем кредит, иначе выдаем.\n",
    "4. Есть ли у клиента другие кредиты? Если есть, то отказываем, иначе выдаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отчасти это и объясняет популярность деревьев. Деревья, кстати, появились еще в 60-ые года, и с тех пор они были важным предметом исследований ~~и где только не применялись.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Плюсы и минусы их вытекают из самой структуры:\n",
    "\n",
    "__PROS:__\n",
    "\n",
    "* Крайне хорошо интерпретируется результат и решение.\n",
    "* Достигают нулевой ошибки на любой выборке при достаточной глубине.\n",
    "\n",
    "__CONS__:\n",
    "\n",
    "* Трудны для оптимизации из-за свой дискретной структуры — дерево нельзя продифференцировать по параметрам и найти с помощью градиентного спуска хотя бы локальный оптимум.\n",
    "* Достаточно трудны в настройке, и все методы их построения на сегодня являются жадными и эвристичными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Матан"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритм построения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево формируется таким образом, что:\n",
    "\n",
    "* каждой внутренней вершине v приписана функция $ \\beta_v : X \\rightarrow \\{ 0,1 \\} $\n",
    "* каждой листовой вершине v приписана метка класса $ c_v \\in Y $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С точки зрения некорого критерия $ Q(X, j, s) $ находим такое разбиение, что $ R_1(j,s) = \\{ x \\space | \\space x_j \\le s \\} $ и $ R_2(j,s) = \\{ x \\space | \\space  x_j > s \\} $. Очевидно, что критерий разбиения $ [ x_j < s ] $ и является функцией $ \\beta_v $, о которой я говорил выше. \n",
    "\n",
    "После чего циклически повторяем данную процедуру разбиения для объектов из левого ($R_1$) и правого ($R_2$) поддеревьев до некорого порога останова. Им может являться:\n",
    "\n",
    "1. Ограничение максимальной глубины дерева.\n",
    "2. Ограничение минимального числа объектов в листе.\n",
    "3. Ограничение максимального количества листьев в дереве.\n",
    "4. Останов в случае, если все объекты в листе относятся к одному классу.\n",
    "5. Требование, что функционал качества при дроблении улучшался как минимум на $s$ процентов.\n",
    "\n",
    "Если при остановке в лист попадают объекты разных классов, то, конечно, предпочтение отдается большинству."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остается вопрос, что же за $ Q(X, j, s) $? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Критерий информативности Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем меньше разброс ответов в вершине, тем лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однозначного способа охарактеризовать разнообразие классов среди объектов в вершине нет, поэтому рассмотрим пример. \n",
    "\n",
    "Пусть в выборке 30 студентов. Известно, что ровно половина из них играют в крикет, но известно, кто. Всего 2 признака: класс, в котором он учится, и  пол студента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Индекс Джини (Gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимизацию критерия Джини можно условно интерпретировать как максимизацию числа пар объектов одного класса, оказавшихся в одном поддереве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.analyticsvidhya.com/blog/wp-content/uploads/2015/01/Decision_Tree_Algorithm1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Разделение по полу (слева)\n",
    "\n",
    "1. Коэффициент Джини для узла __Female__ = $(0.2)*(0.2)+(0.8)*(0.8)=0.68$\n",
    "2. Коэффициент Джини для узла __Male__ = $(0.65)*(0.65)+(0.35)*(0.35)=0.55$\n",
    "3. Взвешенный коэффициент Джини для разделения по полу = $(10/30)*0.68+(20/30)*0.55 $ = __0.59__\n",
    "\n",
    "##### Разделение по классу (справа)\n",
    "\n",
    "1. Коэффициент Джини для узла __Class IX__ = $(0.43)*(0.43)+(0.57)*(0.57)=0.51$\n",
    "2. Коэффициент Джини для узла __Class X__ = $(0.56)*(0.56)+(0.44)*(0.44)=0.51$\n",
    "3. Взвешенный коэффициент Джини для разделения по классу = $(14/30)*0.51+(16/30)*0.51 $ = __0.51__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2015/01/Information_Gain_Decision_Tree2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ I\\left({X;Y}\\right)=H\\left(X\\right)-H\\left({X|Y}\\right)=H\\left(X\\right)+H\\left(Y\\right)-H\\left({X,Y}\\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посчитать энтропию разделения в узле, необходимо:\n",
    "* вычислить энтропию родительского узла;\n",
    "* вычислить энтропию каждого из подузлов, образовавшихся в результате разбиения, после чего вычислить взвешенное среднее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Энтропия родительского узла = $$-(15/30) \\cdot \\log_2 (15/30) – (15/30) log2 (15/30) = 1$$ Единица показывает, что узел не является чистым.\n",
    "2. Энтропия узла __Female__ = $$-(2/10) \\cdot \\log_2 (2/10) – (8/10) \\cdot\\log_2 (8/10) = 0.72$$, а для узла __Male__ $$-(13/20) \\cdot \\log_2 (13/20) – (7/20)\\cdot \\log_2 (7/20) = 0.93$$\n",
    "3. Энтропия для разделения по полу - взвешенное среднее по подузлам: $$ (10/30)*0.72 + (20/30)*0.93 =  \\mathbf{0.86}$$\n",
    "\n",
    "4. Энтропия узла __Class IX__ = $$ -(6/14) \\cdot \\log_2 (6/14) – (8/14) \\cdot \\log_2 (8/14) = 0.99$$,  а для узла __Class X__, $$ -(9/16) \\cdot \\log2 (9/16) – (7/16) \\cdot \\log2 (7/16) = 0.99 $$\n",
    "5. Энтропия для разделения по классу: $$ (14/30)*0.99 + (16/30)*0.99 = \\mathbf{0.99} $$\n",
    "\n",
    "Можно видеть, что энтропия при разделении по полу принимает меньшее значение, поэтому дерево выберет именно __пол__, как признак для разбиения. Взаимная информация может быть тогда вычислена как $1 - Enthropy$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стрижка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент методы стрижки редко используются и не реализованы в большинстве библиотек для анализа данных. Причина заключается в том, что деревья сами по себе являются слабыми алгоритмами и не представляют большого интереса, а при использовании в композициях они либо должны быть переобучены (в случайных лесах), либо должны иметь очень небольшую глубину (в бустинге), из-за чего необходимость в стрижке отпадает."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
